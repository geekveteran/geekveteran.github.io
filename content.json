[{"title":"A Analyst About Modern NBA","date":"2025-04-13T05:59:32.000Z","path":"2025/04/13/A-Analyst-About-Modern-NBA/","text":"","tags":[{"name":"Sports","slug":"Sports","permalink":"https://geekveteran.github.io/tags/Sports/"}]},{"title":"New Revolution About Hash Table","date":"2025-04-13T05:47:10.000Z","path":"2025/04/13/New-revolution-about-hash-table/","text":"","tags":[{"name":"Data Struct","slug":"Data-Struct","permalink":"https://geekveteran.github.io/tags/Data-Struct/"}]},{"title":"A Introduction About Slam(Simultaneous Localization and Mapping)","date":"2025-04-10T04:06:36.000Z","path":"2025/04/10/A-introduction-about-Slam/","text":"OverviewSimultaneous Localization and Mapping (SLAM) is a foundational problem in robotics and computer vision. It involves a mobile system (such as a robot, drone, or autonomous vehicle) that incrementally builds a map of an unknown environment while simultaneously estimating its position within that map. SLAM is essential for any autonomous agent operating in environments where GPS signals are unreliable or unavailable, and pre-existing maps are either incomplete or absent. The Core ProblemSLAM addresses the dual challenge of: Localization: Determining the agent’s position and orientation. Mapping: Building a representation of the environment. These two tasks are interdependent: accurate mapping requires good localization, and good localization requires an accurate map. SLAM seeks to solve this coupled estimation problem in real-time, often under noisy and dynamic conditions. Key Components Component Description Sensor Models Translate raw sensor data (e.g., LiDAR, camera, IMU) into environmental features or constraints. Motion Models Predict how the system moves, often using kinematic or dynamic models. State Estimation Combines sensor inputs and motion predictions to estimate position and map using algorithms like EKF, particle filters, or graph-based methods. Loop Closure Detects when the system returns to a previously visited location, enabling correction of accumulated errors (drift). Types of SLAM Visual SLAM (vSLAM): Utilizes monocular, stereo, or RGB-D cameras to extract visual features. LiDAR SLAM: Employs laser scanners for highly accurate range-based mapping. RGB-D SLAM: Uses color and depth data, popularized by sensors like the Microsoft Kinect. Multi-Sensor SLAM: Fuses data from multiple sensors (e.g., IMU + camera + LiDAR) for robust performance in complex environments. Algorithms and TechniquesCommon SLAM implementations rely on: Extended Kalman Filter (EKF-SLAM) Particle Filter (FastSLAM) Graph-based SLAM (e.g., g2o, pose graph optimization) Visual Odometry + Bundle Adjustment Recent advancements in deep learning and probabilistic programming are also being integrated into SLAM systems. ApplicationsSLAM is used in a wide range of domains, including: Autonomous vehicles (navigation, obstacle avoidance) Robotics (exploration, mapping, localization) Augmented and Virtual Reality (spatial tracking) Drones and UAVs (indoor and outdoor navigation) Planetary exploration (e.g., Mars rovers) Challenges Real-time performance under computation constraints Data association and feature tracking in dynamic scenes Sensor noise and drift accumulation Scalability in large environments Robust loop closure detection References Durrant-Whyte, H., &amp; Bailey, T. (2006). Simultaneous localization and mapping: part I. IEEE Robotics &amp; Automation Magazine. Cadena, C., et al. (2016). Past, present, and future of SLAM: Towards the robust-perception age. IEEE Transactions on Robotics. Thrun, S., Burgard, W., &amp; Fox, D. (2005). Probabilistic Robotics. MIT Press. ConclusionSLAM continues to be a highly active research area and a critical technology for autonomy in unstructured environments. With the integration of advanced sensing, machine learning, and optimization techniques, modern SLAM systems are becoming increasingly robust, scalable, and adaptable across domains.","tags":[{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://geekveteran.github.io/tags/Computer-Vision/"}]},{"title":"Why China Need Reporter and News","date":"2025-04-09T13:52:19.000Z","path":"2025/04/09/Why-china-need-reporter-and-news/","text":"","tags":[{"name":"News","slug":"News","permalink":"https://geekveteran.github.io/tags/News/"}]},{"title":"A Introduction About Computer Vision","date":"2025-04-05T17:02:27.000Z","path":"2025/04/06/A-introduction-about-Computer-Vision/","text":"Introduction to Computer Vision1. Definition and ScopeComputer Vision (CV) is a multidisciplinary field that aims to develop techniques to help computers “see” and understand the content of digital images and videos. It lies at the intersection of artificial intelligence, computer science, and electrical engineering. Key tasks in computer vision: Image classification Object detection Semantic segmentation Instance segmentation Image generation and reconstruction Motion analysis and tracking 2. Biological InspirationComputer vision is inspired by the human visual system. Many image processing operations such as edge detection are modeled after biological processes observed in the retina and visual cortex. 3. Fundamental TechniquesA. Classical Computer VisionTechniques based on handcrafted features and geometry: Edge detection (e.g., Sobel, Canny) Feature descriptors (e.g., SIFT, SURF, ORB) Image transformation and registration 3D reconstruction (e.g., stereo vision, structure from motion) B. Modern Computer Vision (Deep Learning-Based)Relies on learning features from data using deep neural networks: CNNs: Convolutional Neural Networks for spatial feature extraction Object Detection: R-CNN, YOLO, SSD Segmentation: U-Net, Mask R-CNN Transformers: Vision Transformers (ViT), DETR 4. Datasets and BenchmarksStandard datasets that have driven CV research: ImageNet: Image classification COCO: Detection, segmentation Pascal VOC: Classification, detection KITTI, Cityscapes: Autonomous driving Open Images: Large-scale detection and segmentation Competitions like the ImageNet Challenge and COCO Challenge have advanced the state-of-the-art. 5. ApplicationsComputer vision is used in: Healthcare: Radiology, pathology, diagnostics Autonomous vehicles: Lane detection, pedestrian tracking Agriculture: Plant disease detection, yield estimation Security: Face recognition, surveillance Retail: Visual search, customer analytics AR&#x2F;VR: Real-time scene interaction 6. Challenges and Open ProblemsCurrent limitations in CV systems: Sensitivity to variations (lighting, occlusion, pose) Lack of generalization across domains Explainability and trustworthiness Dependence on large labeled datasets Real-time performance constraints 7. Future DirectionsEmerging trends and future research areas: Multi-modal learning (vision + language, audio) Self-supervised and unsupervised learning Efficient deep learning for edge devices Interpretability and fairness in vision models This document provides a foundational understanding of computer vision, its techniques, challenges, and future directions. It serves as a springboard for further exploration into specialized subdomains and research areas.","tags":[{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://geekveteran.github.io/tags/Computer-Vision/"}]},{"title":"Apex Legend Guide","date":"2025-03-26T15:57:08.000Z","path":"2025/03/26/Apex-Legend-Guide/","text":"","tags":[{"name":"FPS Game","slug":"FPS-Game","permalink":"https://geekveteran.github.io/tags/FPS-Game/"}]},{"title":"Warframe Guide For New Tenno","date":"2025-03-26T14:33:23.000Z","path":"2025/03/26/Warframe Guide for new tenno/","text":"IntroductionWarframe is a free play to get source game which has a mod system to set up the Battle Weapon Frame.The mostGreat thing about it is that you can get all the thing by you playing in the game. The Warframe game can be played in many kinds of platforms such as PC, PS4, Xbox.., so you can play it easily. As a new tenno, you may meet many difficult and unknown thing in the game, but do not worry about it. There are some great website you can learn the guide from. Great website about WarframeHow to play as a new tennoyou can learn from the basic thing from Hexo document(https://hexo.io/docs/themes). More about you can look the other code about Hexo theme where in GitHub.","tags":[{"name":"Game","slug":"Game","permalink":"https://geekveteran.github.io/tags/Game/"}]},{"title":"How To Make A Simple Hexo theme","date":"2025-03-25T08:22:11.000Z","path":"2025/03/25/How-to-make-a-simple-Hexo-theme/","text":"Prepare WorkWeb Front DevelopmentFor a new learner, If you want to set a Hexo theme, you should know a simple knowledge about html, css, http,which is about web front development. I do not want to talk about this thing that is the basic knowledge about web development. If you want to learn the knowledge about this, you can watch the guide from the website named Geek for geek. How to make a Hexo ThemeHexo Theme Documentyou can learn from the basic thing from Hexo document(https://hexo.io/docs/themes). More about you can look the other code about Hexo theme where in GitHub.","tags":[{"name":"Hexo Theme","slug":"Hexo-Theme","permalink":"https://geekveteran.github.io/tags/Hexo-Theme/"}]},{"title":"Hello World","date":"2025-02-27T15:57:41.077Z","path":"2025/02/27/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]